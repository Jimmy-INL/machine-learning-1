{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks from scratch with NumPy\n",
    "\n",
    "\n",
    "Consider a classification problem with $K$ classes and input vector $\\mathbf{x}$. Neural networks can be used as discriminative models for the probability $p(\\mathcal{C}_i\\mid \\mathbf{x}, \\boldsymbol{\\theta})$ of a target class $\\mathcal{C}_i$ given the input vector $\\mathbf{x}$, where $\\mathbf{\\Theta}$ denotes all the parameters of the network. In a neural network with $L$ layers, this probability is modeled in the last layer using the softmax function:\n",
    "\n",
    "$$\n",
    "p(\\mathcal{C}_i\\mid \\mathbf{x}, \\mathbf{\\theta}) = a_{iL} = f(z_{iL}) = \\frac{\\exp(z_{iL})}{\\sum_{j=1}^K\\exp(z_{jL})}\n",
    "$$\n",
    "\n",
    "Here $f(\\cdot)$ correspond to the so-called *activation function*, which in this case is the softmax.\n",
    "\n",
    "We can put all the probabilities $a_{iL}$ (with $i = 1, ..., K$) in a column vector, so that the complete output of the network is a vector $\\mathbf{a}_L$ with $K$ elements, containing probabilities for each class. In general, we will call $\\mathbf{a}_l$ the activation output of the $l$-th layer.\n",
    "\n",
    "Note that there is one value of $z_{iL}$ for $i = 1, ..., K$. Each one corresponds to a \"unit\" in the output layer, and is the result of a linear combination of the activations of the previous layer $\\mathbf{a}_{L-1}$ via a set of weights $\\mathbf{w}_{iL}$ and a bias (constant term) $b_{iL}$:\n",
    "\n",
    "$$\n",
    "z_{iL} = \\mathbf{w}_{iL}^T\\mathbf{a}_{L-1} + b_{iL}\n",
    "$$\n",
    "\n",
    "The weights $\\mathbf{w}_{iL}$ are column vectors with a number of elements equal to the number of output units in the previous layer. If we put these in the rows of a matrix $\\mathbf{W}_L$, and all the biases in a column vector $\\mathbf{b}_L$, we can write all the $z_{iL}$ in a single column vector $\\mathbf{z}_L$ given by\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_L = \\mathbf{W}_L\\mathbf{a}_{L-1} + \\mathbf{b}_L\n",
    "$$\n",
    "\n",
    "These equations show how the neural network builds a function composition, from inputs to outputs, in order to model the class probabilities. We can think of the input vector $\\mathbf{x}$ as the activation of layer zero, $\\mathbf{a}_{0}$, which allows us to write down the equations to perform a forward pass on the neural network:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{z}_1 &= \\mathbf{W}_1\\mathbf{x} + \\mathbf{b}_1\\\\\n",
    "\\mathbf{a}_1 &= f_1(\\mathbf{z}_1)\\\\\n",
    "\\mathbf{z}_2 &= \\mathbf{W}_2\\mathbf{a}_1 + \\mathbf{b}_2\\\\\n",
    "\\mathbf{a}_2 &= f_2(\\mathbf{z}_2)\\\\\n",
    "&\\vdots\\\\\n",
    "\\mathbf{z}_L &= \\mathbf{W}_L\\mathbf{a}_{L-1} + \\mathbf{b}_L\\\\\n",
    "\\mathbf{a}_L &= f_L(\\mathbf{z}_L)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "When we say that we \"train\" the neural network, we aim to find the right weights and biases (which we have collectively called $\\boldsymbol{\\theta}$) in order to minimize a certain loss function. If we have a dataset $\\mathbf{D}$ of input vectors and their corresponding class labels, we can compute the likelihood $p(\\mathbf{D}\\mid\\boldsymbol{\\theta})$ of observing the dataset as a function of a particular value of the parameters, which is known as the *likelihood function*, and obtain the set of parameters that maximize it. By doing so, we hope to obtain parameters that not only fit well to the observed data but also generalize to unseen data.\n",
    "\n",
    "For mathematical convenience (such as converting products into sums that simplify differentiation), it is often preferred to work with the logarithm of the likelihood. If we define the task in terms of minimization, we end up with the goal of finding the parameters that minimize the negative log-likelihood<sup>[1](#1)</sup>:\n",
    "\n",
    "$$\n",
    "\\arg\\min_{\\boldsymbol{\\theta}}\\lbrace-\\log p(\\mathbf{D}\\mid\\boldsymbol{\\theta})\\rbrace\n",
    "$$\n",
    "\n",
    "We will solve this optimization problem using gradient descent, by iteratively adjusting the parameters in the direction of decreasing loss. We obtain this direction by calculating the gradient with respect to the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deriving the gradients\n",
    "\n",
    "To specify the label for an input vector we will use a vector with a one hot encoding, so that the vector has $K$ elements, all zero, except for the position of the correct label, which is one. This way, given an observed target vector $\\mathbf{t}$ for an input vector $\\mathbf{x}$, the negative log-likelihood is\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L(\\boldsymbol{\\theta}) = -\\log p(\\mathbf{t}|\\mathbf{x}, \\boldsymbol{\\theta}) &= -\\log\\prod_{i=1}^K p(\\mathcal{C}_i\\mid \\mathbf{x}, \\boldsymbol{\\theta})^{t_i}\\\\\n",
    "&= -\\sum_{i=1}^K t_i\\log p(\\mathcal{C}_i\\mid \\mathbf{x}, \\boldsymbol{\\theta})\\\\\n",
    "&= -\\sum_{i=1}^K t_i\\log\\left(\n",
    "\\frac{\\exp(z_{iL})}{\\sum_{j=1}^K\\exp(z_{jL})}\n",
    "\\right)\\\\\n",
    "&= -\\sum_{i=1}^K t_i\\left(\n",
    "z_{iL} - \\log\\sum_{j=1}^K\\exp(z_{jL}))\n",
    "\\right)\\\\\n",
    "&= z_{mL} - \\log\\sum_{j=1}^K\\exp(z_{jL})\\\\\n",
    "&= z_{mL} - \\log Z\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Where we have defined\n",
    "\n",
    "$$\n",
    "Z = \\sum_{j=1}^K\\exp(z_{jL})\n",
    "$$\n",
    "\n",
    "We now have to calculate the gradients of the loss with respect to every parameter of the neural network. This process consists of a careful application of the chain rule, as we will now see. Starting from the last layer and the weights of the $i$-th unit, we have\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial\\mathbf{w}_{iL}} = \\frac{\\partial L}{\\partial z_{iL}}\\frac{\\partial z_{iL}}{\\partial\\mathbf{w}_{iL}}\n",
    "$$\n",
    "\n",
    "For the first derivative in this expression we have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial z_{iL}} &= \\frac{\\partial}{\\partial z_{iL}}[z_{mL} - \\log Z]\\\\\n",
    "&= \\frac{\\partial}{\\partial z_{iL}}[z_{mL}] - \\frac{\\partial}{\\partial z_{iL}}[\\log Z]\\\\\n",
    "&= \\frac{\\partial}{\\partial z_{iL}}[z_{mL}] - \\frac{1}{Z}\\frac{\\partial}{\\partial z_{iL}}[Z]\\\\\n",
    "&= \\frac{\\partial}{\\partial z_{iL}}[z_{mL}] - \\frac{1}{Z}\\frac{\\partial}{\\partial z_{iL}}\n",
    "\\left[\n",
    "\\sum_{j=1}^K\\exp(z_{jL})\n",
    "\\right]\\\\\n",
    "&= \\frac{\\partial}{\\partial z_{iL}}[z_{mL}] - \\frac{1}{Z}\\frac{\\partial}{\\partial z_{iL}}[\\exp(z_{iL})]\\\\\n",
    "&= \\frac{\\partial}{\\partial z_{iL}}[z_{mL}] - \\frac{1}{Z}\\exp(z_{iL})\\\\\n",
    "&= \\left\\{\n",
    "\\begin{matrix}\n",
    "1 - \\frac{1}{Z}\\exp(z_{iL}) \\text{ if } i = m\\\\\n",
    "- \\frac{1}{Z}\\exp(z_{iL}) \\text{ if } i \\neq m\n",
    "\\end{matrix}\n",
    "\\right.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The next derivative is computed as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial z_{iL}}{\\partial\\mathbf{w}_{iL}} &= \\frac{\\partial}{\\partial \\mathbf{w}_{iL}}[\\mathbf{w}_{iL}^T\\mathbf{a}_{L-1} + b_{iL}] = \\mathbf{a}_{L-1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We therefore have\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial\\mathbf{w}_{iL}} = \\frac{\\partial L}{\\partial z_{iL}}\\mathbf{a}_{L-1}\n",
    "$$\n",
    "\n",
    "This means that for all weights $\\mathbf{w}_{iL}$, the gradient is obtained by multiplying the activation vector of the previous layer by the derivative $\\partial L/\\partial z_{iL}$ (a scalar). The result is a new vector with the same number of elements of $\\mathbf{w}_{iL}$. If we put all these in the rows of a matrix, we end up with a gradient matrix of the same size of $\\mathbf{W}_{L}$. Furthermore, if we put the derivatives $\\partial L/\\partial z_{iL}$, for $i=1,...,K$, in a column vector $\\partial L/\\partial\\mathbf{z}_L$, then the gradient of the loss with respect to the weights $\\mathbf{W}_{L}$ can be calculated in a compact way using an outer product of vectors:\n",
    "\n",
    "$$\n",
    "\\nabla_\\mathbf{W}L = \\frac{\\partial L}{\\partial\\mathbf{z}_L} \\mathbf{a}_{L-1}^T =\n",
    "\\begin{pmatrix}\n",
    "\\mid\\\\ \n",
    "\\partial L/\\partial\\mathbf{z}_L\\\\\n",
    "\\mid\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "-\\;\\mathbf{a}_{L-1}\\;-\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "-\\;\\frac{\\partial L}{\\partial\\mathbf{w}_{1L}}\\;-\\\\\n",
    "-\\;\\frac{\\partial L}{\\partial\\mathbf{w}_{2L}}\\;-\\\\\n",
    "\\vdots\\\\\n",
    "-\\;\\frac{\\partial L}{\\partial\\mathbf{w}_{KL}}\\; -\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\">1</a>. In practice we don't necessarily want to find the minimum for this objective. We could minimize it as much as we can by choosing an appropriately complex model and training for long enough, but we might end up overfitting to the training set and with a model that does not generalize well to unseen data. In the end, we want our model to perform well both on training and test data, and with neural networks there are multiple ways to achieve this, such as weight regularization, dropout, data augmentation, among other techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
